{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from utilities import CustomDataset, trainLoop, testLoop, save_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class SiameseMLPV2(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_layers: List[int], output_size: int):\n",
    "        super(SiameseMLPV2, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_input_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(current_input_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_input_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(current_input_size, output_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.network(x1)\n",
    "        x2 = self.network(x2)\n",
    "        \n",
    "        return torch.norm(x1 - x2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, distance, target):\n",
    "        loss = (distance**2)*target + (1-target)*(torch.max(self.margin - distance, torch.zeros_like(target))**2)\n",
    "        return torch.mean(loss).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVES_FOLDER = \"saves/\"\n",
    "df = pd.read_csv(SAVES_FOLDER + \"dataset.csv\")\n",
    "\n",
    "with open(SAVES_FOLDER + 'id2embedding.pkl', 'rb') as f:\n",
    "    id2embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = [\"left_spec_id\", \"right_spec_id\"]\n",
    "target_col = \"label\"\n",
    "\n",
    "multiplier = 100\n",
    "dataset = CustomDataset(df, features_cols, target_col, id2embedding, multiplier, True)\n",
    "\n",
    "train_size = int(0.75 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "input_size = 768\n",
    "hidden_layers = [256, 128, 64]\n",
    "#input_size = 1024\n",
    "#hidden_layers = [384, 192, 96]\n",
    "\n",
    "output_size = 48\n",
    "model = SiameseMLPV2(input_size, hidden_layers, output_size)\n",
    "\n",
    "margin = multiplier/5.0\n",
    "criterion = CustomLoss(margin=margin)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 114.14025458971659\n",
      "Test Loss: 85.9456, Test Accuracy: 0.4400\n",
      "Precision: 0.3801, Recall: 0.9783, F1-score: 0.5475\n",
      "TP: 271, FP: 442, TN: 81, FN: 6\n",
      "Epoch 2, Loss: 74.73170240402222\n",
      "Test Loss: 75.3530, Test Accuracy: 0.5713\n",
      "Precision: 0.4448, Recall: 0.9603, F1-score: 0.6080\n",
      "TP: 266, FP: 332, TN: 191, FN: 11\n",
      "Epoch 3, Loss: 58.88523851076762\n",
      "Test Loss: 65.5017, Test Accuracy: 0.6062\n",
      "Precision: 0.4668, Recall: 0.9639, F1-score: 0.6290\n",
      "TP: 267, FP: 305, TN: 218, FN: 10\n",
      "Epoch 4, Loss: 50.86327011267344\n",
      "Test Loss: 55.8002, Test Accuracy: 0.6312\n",
      "Precision: 0.4840, Recall: 0.9856, F1-score: 0.6492\n",
      "TP: 273, FP: 291, TN: 232, FN: 4\n",
      "Epoch 5, Loss: 43.3371971420447\n",
      "Test Loss: 49.2094, Test Accuracy: 0.7087\n",
      "Precision: 0.5440, Recall: 0.9819, F1-score: 0.7001\n",
      "TP: 272, FP: 228, TN: 295, FN: 5\n",
      "Epoch 6, Loss: 38.57216187198957\n",
      "Test Loss: 46.5826, Test Accuracy: 0.7025\n",
      "Precision: 0.5386, Recall: 0.9819, F1-score: 0.6957\n",
      "TP: 272, FP: 233, TN: 290, FN: 5\n",
      "Epoch 7, Loss: 33.93764830775559\n",
      "Test Loss: 44.9106, Test Accuracy: 0.7350\n",
      "Precision: 0.5676, Recall: 0.9856, F1-score: 0.7203\n",
      "TP: 273, FP: 208, TN: 315, FN: 4\n",
      "Epoch 8, Loss: 31.68756530528267\n",
      "Test Loss: 40.5392, Test Accuracy: 0.6750\n",
      "Precision: 0.5158, Recall: 1.0000, F1-score: 0.6806\n",
      "TP: 277, FP: 260, TN: 263, FN: 0\n",
      "Epoch 9, Loss: 28.536573885281882\n",
      "Test Loss: 37.3731, Test Accuracy: 0.7525\n",
      "Precision: 0.5842, Recall: 0.9892, F1-score: 0.7346\n",
      "TP: 274, FP: 195, TN: 328, FN: 3\n",
      "Epoch 10, Loss: 26.25232655664285\n",
      "Test Loss: 37.3831, Test Accuracy: 0.7837\n",
      "Precision: 0.6166, Recall: 0.9928, F1-score: 0.7607\n",
      "TP: 275, FP: 171, TN: 352, FN: 2\n",
      "Epoch 11, Loss: 24.443906622678043\n",
      "Test Loss: 37.7367, Test Accuracy: 0.7388\n",
      "Precision: 0.5702, Recall: 0.9964, F1-score: 0.7254\n",
      "TP: 276, FP: 208, TN: 315, FN: 1\n",
      "Epoch 12, Loss: 23.633101053237915\n",
      "Test Loss: 34.7641, Test Accuracy: 0.8087\n",
      "Precision: 0.6449, Recall: 0.9964, F1-score: 0.7830\n",
      "TP: 276, FP: 152, TN: 371, FN: 1\n",
      "Epoch 13, Loss: 22.64015165021643\n",
      "Test Loss: 31.8550, Test Accuracy: 0.7788\n",
      "Precision: 0.6106, Recall: 0.9964, F1-score: 0.7572\n",
      "TP: 276, FP: 176, TN: 347, FN: 1\n",
      "Epoch 14, Loss: 20.922178893983364\n",
      "Test Loss: 30.1311, Test Accuracy: 0.7937\n",
      "Precision: 0.6273, Recall: 0.9964, F1-score: 0.7699\n",
      "TP: 276, FP: 164, TN: 359, FN: 1\n",
      "Epoch 15, Loss: 19.8024096913139\n",
      "Test Loss: 31.9584, Test Accuracy: 0.7750\n",
      "Precision: 0.6066, Recall: 0.9964, F1-score: 0.7541\n",
      "TP: 276, FP: 179, TN: 344, FN: 1\n",
      "Epoch 16, Loss: 18.745775231731436\n",
      "Test Loss: 29.3038, Test Accuracy: 0.7775\n",
      "Precision: 0.6093, Recall: 0.9964, F1-score: 0.7562\n",
      "TP: 276, FP: 177, TN: 346, FN: 1\n",
      "Epoch 17, Loss: 17.73607078817673\n",
      "Test Loss: 31.3564, Test Accuracy: 0.7987\n",
      "Precision: 0.6330, Recall: 0.9964, F1-score: 0.7742\n",
      "TP: 276, FP: 160, TN: 363, FN: 1\n",
      "Epoch 18, Loss: 16.615975435078145\n",
      "Test Loss: 28.0538, Test Accuracy: 0.7650\n",
      "Precision: 0.5961, Recall: 0.9964, F1-score: 0.7459\n",
      "TP: 276, FP: 187, TN: 336, FN: 1\n",
      "Epoch 19, Loss: 16.714304426142093\n",
      "Test Loss: 25.7463, Test Accuracy: 0.7750\n",
      "Precision: 0.6066, Recall: 0.9964, F1-score: 0.7541\n",
      "TP: 276, FP: 179, TN: 344, FN: 1\n",
      "Epoch 20, Loss: 16.198137105802694\n",
      "Test Loss: 26.2573, Test Accuracy: 0.8213\n",
      "Precision: 0.6603, Recall: 0.9964, F1-score: 0.7942\n",
      "TP: 276, FP: 142, TN: 381, FN: 1\n",
      "Epoch 21, Loss: 15.71429577000439\n",
      "Test Loss: 24.5729, Test Accuracy: 0.7913\n",
      "Precision: 0.6244, Recall: 0.9964, F1-score: 0.7677\n",
      "TP: 276, FP: 166, TN: 357, FN: 1\n",
      "Epoch 22, Loss: 14.924231094916662\n",
      "Test Loss: 24.5695, Test Accuracy: 0.8287\n",
      "Precision: 0.6691, Recall: 1.0000, F1-score: 0.8017\n",
      "TP: 277, FP: 137, TN: 386, FN: 0\n",
      "Epoch 23, Loss: 14.198200030177832\n",
      "Test Loss: 26.1071, Test Accuracy: 0.8525\n",
      "Precision: 0.7033, Recall: 0.9928, F1-score: 0.8234\n",
      "TP: 275, FP: 116, TN: 407, FN: 2\n",
      "Epoch 24, Loss: 13.972941110432147\n",
      "Test Loss: 25.9148, Test Accuracy: 0.8575\n",
      "Precision: 0.7084, Recall: 1.0000, F1-score: 0.8293\n",
      "TP: 277, FP: 114, TN: 409, FN: 0\n",
      "Epoch 25, Loss: 13.361748214264711\n",
      "Test Loss: 24.3599, Test Accuracy: 0.8163\n",
      "Precision: 0.6540, Recall: 0.9964, F1-score: 0.7897\n",
      "TP: 276, FP: 146, TN: 377, FN: 1\n",
      "Epoch 26, Loss: 13.392517270644506\n",
      "Test Loss: 22.5894, Test Accuracy: 0.8275\n",
      "Precision: 0.6683, Recall: 0.9964, F1-score: 0.8000\n",
      "TP: 276, FP: 137, TN: 386, FN: 1\n",
      "Epoch 27, Loss: 12.69853855359368\n",
      "Test Loss: 24.3434, Test Accuracy: 0.8250\n",
      "Precision: 0.6643, Recall: 1.0000, F1-score: 0.7983\n",
      "TP: 277, FP: 140, TN: 383, FN: 0\n",
      "Epoch 28, Loss: 12.170894167668497\n",
      "Test Loss: 22.7439, Test Accuracy: 0.8488\n",
      "Precision: 0.6970, Recall: 0.9964, F1-score: 0.8202\n",
      "TP: 276, FP: 120, TN: 403, FN: 1\n",
      "Epoch 29, Loss: 12.413135142860312\n",
      "Test Loss: 22.0641, Test Accuracy: 0.8488\n",
      "Precision: 0.6980, Recall: 0.9928, F1-score: 0.8197\n",
      "TP: 275, FP: 119, TN: 404, FN: 2\n",
      "Epoch 30, Loss: 12.003076898107926\n",
      "Test Loss: 26.9967, Test Accuracy: 0.8050\n",
      "Precision: 0.6410, Recall: 0.9928, F1-score: 0.7790\n",
      "TP: 275, FP: 154, TN: 369, FN: 2\n",
      "Epoch 31, Loss: 12.136300560248396\n",
      "Test Loss: 21.5657, Test Accuracy: 0.8287\n",
      "Precision: 0.6691, Recall: 1.0000, F1-score: 0.8017\n",
      "TP: 277, FP: 137, TN: 386, FN: 0\n",
      "Epoch 32, Loss: 11.033748562807839\n",
      "Test Loss: 21.4831, Test Accuracy: 0.8588\n",
      "Precision: 0.7103, Recall: 1.0000, F1-score: 0.8306\n",
      "TP: 277, FP: 113, TN: 410, FN: 0\n",
      "Epoch 33, Loss: 11.193027911831935\n",
      "Test Loss: 21.7551, Test Accuracy: 0.8512\n",
      "Precision: 0.7005, Recall: 0.9964, F1-score: 0.8227\n",
      "TP: 276, FP: 118, TN: 405, FN: 1\n",
      "Epoch 34, Loss: 10.585498885090152\n",
      "Test Loss: 20.1063, Test Accuracy: 0.8413\n",
      "Precision: 0.6875, Recall: 0.9928, F1-score: 0.8124\n",
      "TP: 275, FP: 125, TN: 398, FN: 2\n",
      "Epoch 35, Loss: 10.555985886342823\n",
      "Test Loss: 18.9445, Test Accuracy: 0.8263\n",
      "Precision: 0.6667, Recall: 0.9964, F1-score: 0.7988\n",
      "TP: 276, FP: 138, TN: 385, FN: 1\n",
      "Epoch 36, Loss: 10.278059651489214\n",
      "Test Loss: 20.9524, Test Accuracy: 0.8488\n",
      "Precision: 0.6970, Recall: 0.9964, F1-score: 0.8202\n",
      "TP: 276, FP: 120, TN: 403, FN: 1\n",
      "Epoch 37, Loss: 9.882477663606405\n",
      "Test Loss: 20.2630, Test Accuracy: 0.8575\n",
      "Precision: 0.7095, Recall: 0.9964, F1-score: 0.8288\n",
      "TP: 276, FP: 113, TN: 410, FN: 1\n",
      "Epoch 38, Loss: 10.054007195631662\n",
      "Test Loss: 20.3410, Test Accuracy: 0.8562\n",
      "Precision: 0.7088, Recall: 0.9928, F1-score: 0.8271\n",
      "TP: 275, FP: 113, TN: 410, FN: 2\n",
      "Epoch 39, Loss: 9.874873349567254\n",
      "Test Loss: 21.5449, Test Accuracy: 0.8438\n",
      "Precision: 0.6910, Recall: 0.9928, F1-score: 0.8148\n",
      "TP: 275, FP: 123, TN: 400, FN: 2\n",
      "Epoch 40, Loss: 9.836583474725485\n",
      "Test Loss: 18.7164, Test Accuracy: 0.8650\n",
      "Precision: 0.7206, Recall: 0.9964, F1-score: 0.8364\n",
      "TP: 276, FP: 107, TN: 416, FN: 1\n",
      "Epoch 41, Loss: 9.23221514805841\n",
      "Test Loss: 18.3777, Test Accuracy: 0.8313\n",
      "Precision: 0.6740, Recall: 0.9928, F1-score: 0.8029\n",
      "TP: 275, FP: 133, TN: 390, FN: 2\n",
      "Epoch 42, Loss: 8.802270512729883\n",
      "Test Loss: 17.8825, Test Accuracy: 0.8712\n",
      "Precision: 0.7314, Recall: 0.9928, F1-score: 0.8423\n",
      "TP: 275, FP: 101, TN: 422, FN: 2\n",
      "Epoch 43, Loss: 8.787779155094176\n",
      "Test Loss: 19.2825, Test Accuracy: 0.8400\n",
      "Precision: 0.6867, Recall: 0.9892, F1-score: 0.8107\n",
      "TP: 274, FP: 125, TN: 398, FN: 3\n",
      "Epoch 44, Loss: 8.94543886286517\n",
      "Test Loss: 17.6730, Test Accuracy: 0.8612\n",
      "Precision: 0.7150, Recall: 0.9964, F1-score: 0.8326\n",
      "TP: 276, FP: 110, TN: 413, FN: 1\n",
      "Epoch 45, Loss: 8.61539384051032\n",
      "Test Loss: 17.9337, Test Accuracy: 0.8550\n",
      "Precision: 0.7080, Recall: 0.9892, F1-score: 0.8253\n",
      "TP: 274, FP: 113, TN: 410, FN: 3\n",
      "Epoch 46, Loss: 8.310637450367212\n",
      "Test Loss: 18.1452, Test Accuracy: 0.8562\n",
      "Precision: 0.7077, Recall: 0.9964, F1-score: 0.8276\n",
      "TP: 276, FP: 114, TN: 409, FN: 1\n",
      "Epoch 47, Loss: 7.824621094937126\n",
      "Test Loss: 18.2734, Test Accuracy: 0.8812\n",
      "Precision: 0.7473, Recall: 0.9928, F1-score: 0.8527\n",
      "TP: 275, FP: 93, TN: 430, FN: 2\n",
      "Epoch 48, Loss: 7.847561359781151\n",
      "Test Loss: 18.3708, Test Accuracy: 0.8650\n",
      "Precision: 0.7230, Recall: 0.9892, F1-score: 0.8354\n",
      "TP: 274, FP: 105, TN: 418, FN: 3\n",
      "Epoch 49, Loss: 8.496493538518747\n",
      "Test Loss: 19.3971, Test Accuracy: 0.8675\n",
      "Precision: 0.7244, Recall: 0.9964, F1-score: 0.8389\n",
      "TP: 276, FP: 105, TN: 418, FN: 1\n",
      "Epoch 50, Loss: 7.766248652040958\n",
      "Test Loss: 17.3628, Test Accuracy: 0.8738\n",
      "Precision: 0.7366, Recall: 0.9892, F1-score: 0.8444\n",
      "TP: 274, FP: 98, TN: 425, FN: 3\n",
      "Epoch 51, Loss: 7.956095683847864\n",
      "Test Loss: 17.5803, Test Accuracy: 0.8438\n",
      "Precision: 0.6900, Recall: 0.9964, F1-score: 0.8154\n",
      "TP: 276, FP: 124, TN: 399, FN: 1\n",
      "Epoch 52, Loss: 7.367822827301037\n",
      "Test Loss: 16.2042, Test Accuracy: 0.8700\n",
      "Precision: 0.7294, Recall: 0.9928, F1-score: 0.8410\n",
      "TP: 275, FP: 102, TN: 421, FN: 2\n",
      "Epoch 53, Loss: 7.427978876171013\n",
      "Test Loss: 16.4595, Test Accuracy: 0.8700\n",
      "Precision: 0.7294, Recall: 0.9928, F1-score: 0.8410\n",
      "TP: 275, FP: 102, TN: 421, FN: 2\n",
      "Epoch 54, Loss: 7.204098977614194\n",
      "Test Loss: 16.1651, Test Accuracy: 0.8838\n",
      "Precision: 0.7514, Recall: 0.9928, F1-score: 0.8554\n",
      "TP: 275, FP: 91, TN: 432, FN: 2\n",
      "Epoch 55, Loss: 6.935771172295014\n",
      "Test Loss: 15.2026, Test Accuracy: 0.8700\n",
      "Precision: 0.7294, Recall: 0.9928, F1-score: 0.8410\n",
      "TP: 275, FP: 102, TN: 421, FN: 2\n",
      "Epoch 56, Loss: 7.014727621444812\n",
      "Test Loss: 18.9638, Test Accuracy: 0.8325\n",
      "Precision: 0.6748, Recall: 0.9964, F1-score: 0.8047\n",
      "TP: 276, FP: 133, TN: 390, FN: 1\n",
      "Epoch 57, Loss: 6.9600249246880415\n",
      "Test Loss: 16.1462, Test Accuracy: 0.8788\n",
      "Precision: 0.7432, Recall: 0.9928, F1-score: 0.8501\n",
      "TP: 275, FP: 95, TN: 428, FN: 2\n",
      "Epoch 58, Loss: 6.868879809163821\n",
      "Test Loss: 19.8664, Test Accuracy: 0.8425\n",
      "Precision: 0.6883, Recall: 0.9964, F1-score: 0.8142\n",
      "TP: 276, FP: 125, TN: 398, FN: 1\n",
      "Epoch 59, Loss: 6.65892216835171\n",
      "Test Loss: 17.4643, Test Accuracy: 0.8825\n",
      "Precision: 0.7507, Recall: 0.9892, F1-score: 0.8536\n",
      "TP: 274, FP: 91, TN: 432, FN: 3\n",
      "Epoch 60, Loss: 6.752346663450202\n",
      "Test Loss: 16.8623, Test Accuracy: 0.8775\n",
      "Precision: 0.7399, Recall: 0.9964, F1-score: 0.8492\n",
      "TP: 276, FP: 97, TN: 426, FN: 1\n",
      "Epoch 61, Loss: 6.908767430220226\n",
      "Test Loss: 14.5529, Test Accuracy: 0.8612\n",
      "Precision: 0.7150, Recall: 0.9964, F1-score: 0.8326\n",
      "TP: 276, FP: 110, TN: 413, FN: 1\n",
      "Epoch 62, Loss: 6.319745796918869\n",
      "Test Loss: 16.1109, Test Accuracy: 0.8775\n",
      "Precision: 0.7412, Recall: 0.9928, F1-score: 0.8488\n",
      "TP: 275, FP: 96, TN: 427, FN: 2\n",
      "Epoch 63, Loss: 6.019737277925015\n",
      "Test Loss: 15.9932, Test Accuracy: 0.8688\n",
      "Precision: 0.7275, Recall: 0.9928, F1-score: 0.8397\n",
      "TP: 275, FP: 103, TN: 420, FN: 2\n",
      "Epoch 64, Loss: 6.222886615296205\n",
      "Test Loss: 17.0322, Test Accuracy: 0.8875\n",
      "Precision: 0.7590, Recall: 0.9892, F1-score: 0.8589\n",
      "TP: 274, FP: 87, TN: 436, FN: 3\n",
      "Epoch 65, Loss: 6.353723455996175\n",
      "Test Loss: 14.9804, Test Accuracy: 0.8375\n",
      "Precision: 0.6824, Recall: 0.9928, F1-score: 0.8088\n",
      "TP: 275, FP: 128, TN: 395, FN: 2\n",
      "Epoch 66, Loss: 5.969118647165597\n",
      "Test Loss: 16.8251, Test Accuracy: 0.8700\n",
      "Precision: 0.7294, Recall: 0.9928, F1-score: 0.8410\n",
      "TP: 275, FP: 102, TN: 421, FN: 2\n",
      "Epoch 67, Loss: 6.365750997165839\n",
      "Test Loss: 17.1958, Test Accuracy: 0.8838\n",
      "Precision: 0.7514, Recall: 0.9928, F1-score: 0.8554\n",
      "TP: 275, FP: 91, TN: 432, FN: 2\n",
      "Epoch 68, Loss: 6.236302279829979\n",
      "Test Loss: 15.0105, Test Accuracy: 0.8888\n",
      "Precision: 0.7597, Recall: 0.9928, F1-score: 0.8607\n",
      "TP: 275, FP: 87, TN: 436, FN: 2\n",
      "Epoch 69, Loss: 6.1069460644883415\n",
      "Test Loss: 13.9673, Test Accuracy: 0.8862\n",
      "Precision: 0.7555, Recall: 0.9928, F1-score: 0.8580\n",
      "TP: 275, FP: 89, TN: 434, FN: 2\n",
      "Epoch 70, Loss: 5.937192070893944\n",
      "Test Loss: 15.0082, Test Accuracy: 0.8662\n",
      "Precision: 0.7225, Recall: 0.9964, F1-score: 0.8376\n",
      "TP: 276, FP: 106, TN: 417, FN: 1\n",
      "Epoch 71, Loss: 6.420328168893854\n",
      "Test Loss: 13.8794, Test Accuracy: 0.8925\n",
      "Precision: 0.7660, Recall: 0.9928, F1-score: 0.8648\n",
      "TP: 275, FP: 84, TN: 439, FN: 2\n",
      "Epoch 72, Loss: 5.985472769088422\n",
      "Test Loss: 14.3468, Test Accuracy: 0.8750\n",
      "Precision: 0.7373, Recall: 0.9928, F1-score: 0.8462\n",
      "TP: 275, FP: 98, TN: 425, FN: 2\n",
      "Epoch 73, Loss: 4.920269747580169\n",
      "Test Loss: 20.3329, Test Accuracy: 0.8988\n",
      "Precision: 0.7768, Recall: 0.9928, F1-score: 0.8716\n",
      "TP: 275, FP: 79, TN: 444, FN: 2\n",
      "Epoch 74, Loss: 5.513873157594353\n",
      "Test Loss: 16.7970, Test Accuracy: 0.8838\n",
      "Precision: 0.7514, Recall: 0.9928, F1-score: 0.8554\n",
      "TP: 275, FP: 91, TN: 432, FN: 2\n",
      "Epoch 75, Loss: 5.555969813459087\n",
      "Test Loss: 13.3225, Test Accuracy: 0.8762\n",
      "Precision: 0.7392, Recall: 0.9928, F1-score: 0.8475\n",
      "TP: 275, FP: 97, TN: 426, FN: 2\n",
      "Epoch 76, Loss: 6.049009032951047\n",
      "Test Loss: 13.5808, Test Accuracy: 0.8938\n",
      "Precision: 0.7682, Recall: 0.9928, F1-score: 0.8661\n",
      "TP: 275, FP: 83, TN: 440, FN: 2\n",
      "Epoch 77, Loss: 5.304749374364813\n",
      "Test Loss: 13.2737, Test Accuracy: 0.8850\n",
      "Precision: 0.7534, Recall: 0.9928, F1-score: 0.8567\n",
      "TP: 275, FP: 90, TN: 433, FN: 2\n",
      "Epoch 78, Loss: 5.3859327592762805\n",
      "Test Loss: 13.3300, Test Accuracy: 0.8812\n",
      "Precision: 0.7473, Recall: 0.9928, F1-score: 0.8527\n",
      "TP: 275, FP: 93, TN: 430, FN: 2\n",
      "Epoch 79, Loss: 5.223398715281704\n",
      "Test Loss: 15.3280, Test Accuracy: 0.8988\n",
      "Precision: 0.7768, Recall: 0.9928, F1-score: 0.8716\n",
      "TP: 275, FP: 79, TN: 444, FN: 2\n",
      "Epoch 80, Loss: 5.127740857352813\n",
      "Test Loss: 12.3271, Test Accuracy: 0.8812\n",
      "Precision: 0.7473, Recall: 0.9928, F1-score: 0.8527\n",
      "TP: 275, FP: 93, TN: 430, FN: 2\n",
      "Epoch 81, Loss: 5.405176776970427\n",
      "Test Loss: 14.5919, Test Accuracy: 0.8712\n",
      "Precision: 0.7302, Recall: 0.9964, F1-score: 0.8427\n",
      "TP: 276, FP: 102, TN: 421, FN: 1\n",
      "Epoch 82, Loss: 5.223087020739913\n",
      "Test Loss: 15.3868, Test Accuracy: 0.8888\n",
      "Precision: 0.7597, Recall: 0.9928, F1-score: 0.8607\n",
      "TP: 275, FP: 87, TN: 436, FN: 2\n",
      "Epoch 83, Loss: 4.59473475150764\n",
      "Test Loss: 13.2103, Test Accuracy: 0.8862\n",
      "Precision: 0.7555, Recall: 0.9928, F1-score: 0.8580\n",
      "TP: 275, FP: 89, TN: 434, FN: 2\n",
      "Epoch 84, Loss: 5.108886334318668\n",
      "Test Loss: 13.9438, Test Accuracy: 0.8988\n",
      "Precision: 0.7768, Recall: 0.9928, F1-score: 0.8716\n",
      "TP: 275, FP: 79, TN: 444, FN: 2\n",
      "Epoch 85, Loss: 4.702707008222739\n",
      "Test Loss: 14.0738, Test Accuracy: 0.8788\n",
      "Precision: 0.7432, Recall: 0.9928, F1-score: 0.8501\n",
      "TP: 275, FP: 95, TN: 428, FN: 2\n",
      "Epoch 86, Loss: 4.415483938658144\n",
      "Test Loss: 15.5919, Test Accuracy: 0.9000\n",
      "Precision: 0.7790, Recall: 0.9928, F1-score: 0.8730\n",
      "TP: 275, FP: 78, TN: 445, FN: 2\n",
      "Epoch 87, Loss: 4.8215786652839965\n",
      "Test Loss: 14.3133, Test Accuracy: 0.8638\n",
      "Precision: 0.7199, Recall: 0.9928, F1-score: 0.8346\n",
      "TP: 275, FP: 107, TN: 416, FN: 2\n",
      "Epoch 88, Loss: 4.312753801258902\n",
      "Test Loss: 12.8805, Test Accuracy: 0.9025\n",
      "Precision: 0.7835, Recall: 0.9928, F1-score: 0.8758\n",
      "TP: 275, FP: 76, TN: 447, FN: 2\n",
      "Epoch 89, Loss: 4.7630206405371425\n",
      "Test Loss: 12.9253, Test Accuracy: 0.8888\n",
      "Precision: 0.7597, Recall: 0.9928, F1-score: 0.8607\n",
      "TP: 275, FP: 87, TN: 436, FN: 2\n",
      "Epoch 90, Loss: 4.030207289916774\n",
      "Test Loss: 11.3898, Test Accuracy: 0.8938\n",
      "Precision: 0.7682, Recall: 0.9928, F1-score: 0.8661\n",
      "TP: 275, FP: 83, TN: 440, FN: 2\n",
      "Epoch 91, Loss: 3.925700115497845\n",
      "Test Loss: 11.4262, Test Accuracy: 0.9113\n",
      "Precision: 0.7994, Recall: 0.9928, F1-score: 0.8857\n",
      "TP: 275, FP: 69, TN: 454, FN: 2\n",
      "Epoch 92, Loss: 3.6560588938510046\n",
      "Test Loss: 16.4812, Test Accuracy: 0.9087\n",
      "Precision: 0.7948, Recall: 0.9928, F1-score: 0.8828\n",
      "TP: 275, FP: 71, TN: 452, FN: 2\n",
      "Epoch 93, Loss: 4.094078956649949\n",
      "Test Loss: 12.4124, Test Accuracy: 0.9012\n",
      "Precision: 0.7812, Recall: 0.9928, F1-score: 0.8744\n",
      "TP: 275, FP: 77, TN: 446, FN: 2\n",
      "Epoch 94, Loss: 3.565557406761994\n",
      "Test Loss: 13.1599, Test Accuracy: 0.8862\n",
      "Precision: 0.7555, Recall: 0.9928, F1-score: 0.8580\n",
      "TP: 275, FP: 89, TN: 434, FN: 2\n",
      "Epoch 95, Loss: 3.977055095527321\n",
      "Test Loss: 11.9426, Test Accuracy: 0.8875\n",
      "Precision: 0.7576, Recall: 0.9928, F1-score: 0.8594\n",
      "TP: 275, FP: 88, TN: 435, FN: 2\n",
      "Epoch 96, Loss: 3.686270880076724\n",
      "Test Loss: 13.4760, Test Accuracy: 0.9025\n",
      "Precision: 0.7835, Recall: 0.9928, F1-score: 0.8758\n",
      "TP: 275, FP: 76, TN: 447, FN: 2\n",
      "Epoch 97, Loss: 3.6678602004299563\n",
      "Test Loss: 11.8752, Test Accuracy: 0.8850\n",
      "Precision: 0.7534, Recall: 0.9928, F1-score: 0.8567\n",
      "TP: 275, FP: 90, TN: 433, FN: 2\n",
      "Epoch 98, Loss: 3.7211186936932306\n",
      "Test Loss: 11.2653, Test Accuracy: 0.8950\n",
      "Precision: 0.7703, Recall: 0.9928, F1-score: 0.8675\n",
      "TP: 275, FP: 82, TN: 441, FN: 2\n",
      "Epoch 99, Loss: 3.5819404124220213\n",
      "Test Loss: 12.4042, Test Accuracy: 0.9100\n",
      "Precision: 0.7971, Recall: 0.9928, F1-score: 0.8842\n",
      "TP: 275, FP: 70, TN: 453, FN: 2\n",
      "Epoch 100, Loss: 3.4894133785615367\n",
      "Test Loss: 11.5365, Test Accuracy: 0.9025\n",
      "Precision: 0.7835, Recall: 0.9928, F1-score: 0.8758\n",
      "TP: 275, FP: 76, TN: 447, FN: 2\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "stats = dict()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loss = trainLoop(model, optimizer, criterion, train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
    "    pred_function = lambda x: x < margin\n",
    "    testLoop(model, criterion, test_loader, pred_function, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_stats(\"MLP_V2_bert_base\", stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
