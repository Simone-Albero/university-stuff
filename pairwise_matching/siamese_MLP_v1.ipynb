{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utilities import CustomDataset, trainLoop, testLoop, save_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseMLPV1(nn.Module):\n",
    "    def __init__(self, input_size = 768, hidden_size1 = 256, hidden_size2 = 128, output_size = 1):\n",
    "        super(SiameseMLPV1, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output_A = self.forward_once(x1)\n",
    "        output_B = self.forward_once(x2)\n",
    "        return torch.sigmoid(self.fc3(torch.abs(output_A - output_B))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVES_FOLDER = \"saves/\"\n",
    "df = pd.read_csv(SAVES_FOLDER + \"dataset.csv\")\n",
    "\n",
    "with open(SAVES_FOLDER + 'id2embedding.pkl', 'rb') as f:\n",
    "    id2embedding = pickle.load(f)\n",
    "\n",
    "#model = SiameseMLPV1(1024, 512, 256)\n",
    "model = SiameseMLPV1()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "features_cols = [\"left_spec_id\", \"right_spec_id\"]\n",
    "target_col = \"label\"\n",
    "dataset = CustomDataset(df, features_cols, target_col, id2embedding)\n",
    "\n",
    "train_size = int(0.75 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6731143421248386\n",
      "Test Loss: 0.6371, Test Accuracy: 0.3350\n",
      "Precision: 0.3350, Recall: 1.0000, F1-score: 0.5019\n",
      "TP: 268, FP: 532, TN: 0, FN: 0\n",
      "Epoch 2, Loss: 0.6237532135687376\n",
      "Test Loss: 0.5868, Test Accuracy: 0.3538\n",
      "Precision: 0.3414, Recall: 1.0000, F1-score: 0.5090\n",
      "TP: 268, FP: 517, TN: 15, FN: 0\n",
      "Epoch 3, Loss: 0.589394831343701\n",
      "Test Loss: 0.5647, Test Accuracy: 0.4350\n",
      "Precision: 0.3711, Recall: 0.9888, F1-score: 0.5397\n",
      "TP: 265, FP: 449, TN: 83, FN: 3\n",
      "Epoch 4, Loss: 0.5737387914406625\n",
      "Test Loss: 0.5555, Test Accuracy: 0.4975\n",
      "Precision: 0.3972, Recall: 0.9664, F1-score: 0.5630\n",
      "TP: 259, FP: 393, TN: 139, FN: 9\n",
      "Epoch 5, Loss: 0.5624395389305917\n",
      "Test Loss: 0.5483, Test Accuracy: 0.5200\n",
      "Precision: 0.4073, Recall: 0.9515, F1-score: 0.5705\n",
      "TP: 255, FP: 371, TN: 161, FN: 13\n",
      "Epoch 6, Loss: 0.5504742641198007\n",
      "Test Loss: 0.5430, Test Accuracy: 0.5262\n",
      "Precision: 0.4115, Recall: 0.9627, F1-score: 0.5765\n",
      "TP: 258, FP: 369, TN: 163, FN: 10\n",
      "Epoch 7, Loss: 0.5416155614350971\n",
      "Test Loss: 0.5372, Test Accuracy: 0.5587\n",
      "Precision: 0.4281, Recall: 0.9440, F1-score: 0.5891\n",
      "TP: 253, FP: 338, TN: 194, FN: 15\n",
      "Epoch 8, Loss: 0.5298725060726467\n",
      "Test Loss: 0.5298, Test Accuracy: 0.5725\n",
      "Precision: 0.4369, Recall: 0.9552, F1-score: 0.5995\n",
      "TP: 256, FP: 330, TN: 202, FN: 12\n",
      "Epoch 9, Loss: 0.5232228048537907\n",
      "Test Loss: 0.5227, Test Accuracy: 0.5863\n",
      "Precision: 0.4450, Recall: 0.9515, F1-score: 0.6064\n",
      "TP: 255, FP: 318, TN: 214, FN: 13\n",
      "Epoch 10, Loss: 0.5110498690291455\n",
      "Test Loss: 0.5152, Test Accuracy: 0.6150\n",
      "Precision: 0.4631, Recall: 0.9366, F1-score: 0.6198\n",
      "TP: 251, FP: 291, TN: 241, FN: 17\n",
      "Epoch 11, Loss: 0.49987185785644933\n",
      "Test Loss: 0.5089, Test Accuracy: 0.6475\n",
      "Precision: 0.4864, Recall: 0.9366, F1-score: 0.6403\n",
      "TP: 251, FP: 265, TN: 267, FN: 17\n",
      "Epoch 12, Loss: 0.49074803763314295\n",
      "Test Loss: 0.5000, Test Accuracy: 0.6388\n",
      "Precision: 0.4804, Recall: 0.9627, F1-score: 0.6410\n",
      "TP: 258, FP: 279, TN: 253, FN: 10\n",
      "Epoch 13, Loss: 0.4794441587046573\n",
      "Test Loss: 0.4931, Test Accuracy: 0.6475\n",
      "Precision: 0.4867, Recall: 0.9552, F1-score: 0.6448\n",
      "TP: 256, FP: 270, TN: 262, FN: 12\n",
      "Epoch 14, Loss: 0.46957305936436905\n",
      "Test Loss: 0.4833, Test Accuracy: 0.6713\n",
      "Precision: 0.5049, Recall: 0.9552, F1-score: 0.6606\n",
      "TP: 256, FP: 251, TN: 281, FN: 12\n",
      "Epoch 15, Loss: 0.45775684949598816\n",
      "Test Loss: 0.4765, Test Accuracy: 0.6600\n",
      "Precision: 0.4961, Recall: 0.9590, F1-score: 0.6539\n",
      "TP: 257, FP: 261, TN: 271, FN: 11\n",
      "Epoch 16, Loss: 0.44508373580480876\n",
      "Test Loss: 0.4674, Test Accuracy: 0.6825\n",
      "Precision: 0.5140, Recall: 0.9590, F1-score: 0.6693\n",
      "TP: 257, FP: 243, TN: 289, FN: 11\n",
      "Epoch 17, Loss: 0.4365935051127484\n",
      "Test Loss: 0.4575, Test Accuracy: 0.7000\n",
      "Precision: 0.5293, Recall: 0.9440, F1-score: 0.6783\n",
      "TP: 253, FP: 225, TN: 307, FN: 15\n",
      "Epoch 18, Loss: 0.42419952154159546\n",
      "Test Loss: 0.4515, Test Accuracy: 0.6937\n",
      "Precision: 0.5233, Recall: 0.9627, F1-score: 0.6781\n",
      "TP: 258, FP: 235, TN: 297, FN: 10\n",
      "Epoch 19, Loss: 0.4124408615262885\n",
      "Test Loss: 0.4400, Test Accuracy: 0.7288\n",
      "Precision: 0.5553, Recall: 0.9552, F1-score: 0.7023\n",
      "TP: 256, FP: 205, TN: 327, FN: 12\n",
      "Epoch 20, Loss: 0.40209947840163585\n",
      "Test Loss: 0.4316, Test Accuracy: 0.7325\n",
      "Precision: 0.5587, Recall: 0.9590, F1-score: 0.7060\n",
      "TP: 257, FP: 203, TN: 329, FN: 11\n",
      "Epoch 21, Loss: 0.3901951932593396\n",
      "Test Loss: 0.4228, Test Accuracy: 0.7450\n",
      "Precision: 0.5721, Recall: 0.9478, F1-score: 0.7135\n",
      "TP: 254, FP: 190, TN: 342, FN: 14\n",
      "Epoch 22, Loss: 0.3808775136345311\n",
      "Test Loss: 0.4154, Test Accuracy: 0.7512\n",
      "Precision: 0.5775, Recall: 0.9590, F1-score: 0.7209\n",
      "TP: 257, FP: 188, TN: 344, FN: 11\n",
      "Epoch 23, Loss: 0.36590326459784256\n",
      "Test Loss: 0.4096, Test Accuracy: 0.7650\n",
      "Precision: 0.5926, Recall: 0.9552, F1-score: 0.7314\n",
      "TP: 256, FP: 176, TN: 356, FN: 12\n",
      "Epoch 24, Loss: 0.3580496028849953\n",
      "Test Loss: 0.4012, Test Accuracy: 0.7675\n",
      "Precision: 0.5953, Recall: 0.9552, F1-score: 0.7335\n",
      "TP: 256, FP: 174, TN: 358, FN: 12\n",
      "Epoch 25, Loss: 0.3462582152140768\n",
      "Test Loss: 0.3942, Test Accuracy: 0.7800\n",
      "Precision: 0.6090, Recall: 0.9590, F1-score: 0.7449\n",
      "TP: 257, FP: 165, TN: 367, FN: 11\n",
      "Epoch 26, Loss: 0.33735346009856776\n",
      "Test Loss: 0.3875, Test Accuracy: 0.7800\n",
      "Precision: 0.6090, Recall: 0.9590, F1-score: 0.7449\n",
      "TP: 257, FP: 165, TN: 367, FN: 11\n",
      "Epoch 27, Loss: 0.32842666851846797\n",
      "Test Loss: 0.3868, Test Accuracy: 0.7850\n",
      "Precision: 0.6165, Recall: 0.9478, F1-score: 0.7471\n",
      "TP: 254, FP: 158, TN: 374, FN: 14\n",
      "Epoch 28, Loss: 0.3192138056221761\n",
      "Test Loss: 0.3761, Test Accuracy: 0.8000\n",
      "Precision: 0.6343, Recall: 0.9515, F1-score: 0.7612\n",
      "TP: 255, FP: 147, TN: 385, FN: 13\n",
      "Epoch 29, Loss: 0.3096477189346364\n",
      "Test Loss: 0.3700, Test Accuracy: 0.7925\n",
      "Precision: 0.6244, Recall: 0.9552, F1-score: 0.7552\n",
      "TP: 256, FP: 154, TN: 378, FN: 12\n",
      "Epoch 30, Loss: 0.29983508273174886\n",
      "Test Loss: 0.3676, Test Accuracy: 0.8013\n",
      "Precision: 0.6380, Recall: 0.9403, F1-score: 0.7602\n",
      "TP: 252, FP: 143, TN: 389, FN: 16\n",
      "Epoch 31, Loss: 0.29268148580664083\n",
      "Test Loss: 0.3612, Test Accuracy: 0.7913\n",
      "Precision: 0.6247, Recall: 0.9440, F1-score: 0.7519\n",
      "TP: 253, FP: 152, TN: 380, FN: 15\n",
      "Epoch 32, Loss: 0.28359596941031906\n",
      "Test Loss: 0.3567, Test Accuracy: 0.8100\n",
      "Precision: 0.6480, Recall: 0.9478, F1-score: 0.7697\n",
      "TP: 254, FP: 138, TN: 394, FN: 14\n",
      "Epoch 33, Loss: 0.2766117853553672\n",
      "Test Loss: 0.3547, Test Accuracy: 0.8125\n",
      "Precision: 0.6521, Recall: 0.9440, F1-score: 0.7713\n",
      "TP: 253, FP: 135, TN: 397, FN: 15\n",
      "Epoch 34, Loss: 0.2702036590168351\n",
      "Test Loss: 0.3517, Test Accuracy: 0.8213\n",
      "Precision: 0.6632, Recall: 0.9478, F1-score: 0.7803\n",
      "TP: 254, FP: 129, TN: 403, FN: 14\n",
      "Epoch 35, Loss: 0.262528657913208\n",
      "Test Loss: 0.3486, Test Accuracy: 0.8175\n",
      "Precision: 0.6622, Recall: 0.9291, F1-score: 0.7733\n",
      "TP: 249, FP: 127, TN: 405, FN: 19\n",
      "Epoch 36, Loss: 0.25355121140417297\n",
      "Test Loss: 0.3414, Test Accuracy: 0.8225\n",
      "Precision: 0.6649, Recall: 0.9478, F1-score: 0.7815\n",
      "TP: 254, FP: 128, TN: 404, FN: 14\n",
      "Epoch 37, Loss: 0.250554516127235\n",
      "Test Loss: 0.3461, Test Accuracy: 0.8313\n",
      "Precision: 0.6802, Recall: 0.9366, F1-score: 0.7881\n",
      "TP: 251, FP: 118, TN: 414, FN: 17\n",
      "Epoch 38, Loss: 0.2433743233743467\n",
      "Test Loss: 0.3398, Test Accuracy: 0.8313\n",
      "Precision: 0.6773, Recall: 0.9478, F1-score: 0.7900\n",
      "TP: 254, FP: 121, TN: 411, FN: 14\n",
      "Epoch 39, Loss: 0.23701919576055125\n",
      "Test Loss: 0.3358, Test Accuracy: 0.8313\n",
      "Precision: 0.6832, Recall: 0.9254, F1-score: 0.7861\n",
      "TP: 248, FP: 115, TN: 417, FN: 20\n",
      "Epoch 40, Loss: 0.23259611074861727\n",
      "Test Loss: 0.3349, Test Accuracy: 0.8438\n",
      "Precision: 0.6938, Recall: 0.9552, F1-score: 0.8038\n",
      "TP: 256, FP: 113, TN: 419, FN: 12\n",
      "Epoch 41, Loss: 0.22758698698721433\n",
      "Test Loss: 0.3328, Test Accuracy: 0.8413\n",
      "Precision: 0.6932, Recall: 0.9440, F1-score: 0.7994\n",
      "TP: 253, FP: 112, TN: 420, FN: 15\n",
      "Epoch 42, Loss: 0.21979556154263646\n",
      "Test Loss: 0.3340, Test Accuracy: 0.8450\n",
      "Precision: 0.7000, Recall: 0.9403, F1-score: 0.8025\n",
      "TP: 252, FP: 108, TN: 424, FN: 16\n",
      "Epoch 43, Loss: 0.21513881102988594\n",
      "Test Loss: 0.3270, Test Accuracy: 0.8413\n",
      "Precision: 0.6942, Recall: 0.9403, F1-score: 0.7987\n",
      "TP: 252, FP: 111, TN: 421, FN: 16\n",
      "Epoch 44, Loss: 0.21136001105371274\n",
      "Test Loss: 0.3278, Test Accuracy: 0.8500\n",
      "Precision: 0.7079, Recall: 0.9403, F1-score: 0.8077\n",
      "TP: 252, FP: 104, TN: 428, FN: 16\n",
      "Epoch 45, Loss: 0.20514568411990217\n",
      "Test Loss: 0.3263, Test Accuracy: 0.8438\n",
      "Precision: 0.6959, Recall: 0.9478, F1-score: 0.8025\n",
      "TP: 254, FP: 111, TN: 421, FN: 14\n",
      "Epoch 46, Loss: 0.20022828798545034\n",
      "Test Loss: 0.3246, Test Accuracy: 0.8488\n",
      "Precision: 0.7082, Recall: 0.9328, F1-score: 0.8052\n",
      "TP: 250, FP: 103, TN: 429, FN: 18\n",
      "Epoch 47, Loss: 0.19688112249499873\n",
      "Test Loss: 0.3212, Test Accuracy: 0.8512\n",
      "Precision: 0.7110, Recall: 0.9366, F1-score: 0.8084\n",
      "TP: 251, FP: 102, TN: 430, FN: 17\n",
      "Epoch 48, Loss: 0.18987514294291796\n",
      "Test Loss: 0.3254, Test Accuracy: 0.8512\n",
      "Precision: 0.7135, Recall: 0.9291, F1-score: 0.8071\n",
      "TP: 249, FP: 100, TN: 432, FN: 19\n",
      "Epoch 49, Loss: 0.18721720046902957\n",
      "Test Loss: 0.3239, Test Accuracy: 0.8475\n",
      "Precision: 0.7039, Recall: 0.9403, F1-score: 0.8051\n",
      "TP: 252, FP: 106, TN: 426, FN: 16\n",
      "Epoch 50, Loss: 0.18422236450408636\n",
      "Test Loss: 0.3228, Test Accuracy: 0.8500\n",
      "Precision: 0.7114, Recall: 0.9291, F1-score: 0.8058\n",
      "TP: 249, FP: 101, TN: 431, FN: 19\n",
      "Epoch 51, Loss: 0.17777280862394132\n",
      "Test Loss: 0.3214, Test Accuracy: 0.8550\n",
      "Precision: 0.7197, Recall: 0.9291, F1-score: 0.8111\n",
      "TP: 249, FP: 97, TN: 435, FN: 19\n",
      "Epoch 52, Loss: 0.17600967146848379\n",
      "Test Loss: 0.3211, Test Accuracy: 0.8525\n",
      "Precision: 0.7143, Recall: 0.9328, F1-score: 0.8091\n",
      "TP: 250, FP: 100, TN: 432, FN: 18\n",
      "Epoch 53, Loss: 0.17194782452363716\n",
      "Test Loss: 0.3210, Test Accuracy: 0.8525\n",
      "Precision: 0.7155, Recall: 0.9291, F1-score: 0.8084\n",
      "TP: 249, FP: 99, TN: 433, FN: 19\n",
      "Epoch 54, Loss: 0.1665915980150825\n",
      "Test Loss: 0.3197, Test Accuracy: 0.8625\n",
      "Precision: 0.7324, Recall: 0.9291, F1-score: 0.8191\n",
      "TP: 249, FP: 91, TN: 441, FN: 19\n",
      "Epoch 55, Loss: 0.1641907121397947\n",
      "Test Loss: 0.3194, Test Accuracy: 0.8538\n",
      "Precision: 0.7151, Recall: 0.9366, F1-score: 0.8110\n",
      "TP: 251, FP: 100, TN: 432, FN: 17\n",
      "Epoch 56, Loss: 0.15952366316004804\n",
      "Test Loss: 0.3177, Test Accuracy: 0.8575\n",
      "Precision: 0.7278, Recall: 0.9179, F1-score: 0.8119\n",
      "TP: 246, FP: 92, TN: 440, FN: 22\n",
      "Epoch 57, Loss: 0.1553400082415656\n",
      "Test Loss: 0.3158, Test Accuracy: 0.8688\n",
      "Precision: 0.7418, Recall: 0.9328, F1-score: 0.8264\n",
      "TP: 250, FP: 87, TN: 445, FN: 18\n",
      "Epoch 58, Loss: 0.15467223152518272\n",
      "Test Loss: 0.3156, Test Accuracy: 0.8612\n",
      "Precision: 0.7302, Recall: 0.9291, F1-score: 0.8177\n",
      "TP: 249, FP: 92, TN: 440, FN: 19\n",
      "Epoch 59, Loss: 0.1505510252165167\n",
      "Test Loss: 0.3169, Test Accuracy: 0.8612\n",
      "Precision: 0.7302, Recall: 0.9291, F1-score: 0.8177\n",
      "TP: 249, FP: 92, TN: 440, FN: 19\n",
      "Epoch 60, Loss: 0.14698664667574982\n",
      "Test Loss: 0.3181, Test Accuracy: 0.8588\n",
      "Precision: 0.7259, Recall: 0.9291, F1-score: 0.8151\n",
      "TP: 249, FP: 94, TN: 438, FN: 19\n",
      "Epoch 61, Loss: 0.14364511284388995\n",
      "Test Loss: 0.3198, Test Accuracy: 0.8612\n",
      "Precision: 0.7329, Recall: 0.9216, F1-score: 0.8165\n",
      "TP: 247, FP: 90, TN: 442, FN: 21\n",
      "Epoch 62, Loss: 0.14126939326524734\n",
      "Test Loss: 0.3155, Test Accuracy: 0.8650\n",
      "Precision: 0.7395, Recall: 0.9216, F1-score: 0.8206\n",
      "TP: 247, FP: 87, TN: 445, FN: 21\n",
      "Epoch 63, Loss: 0.13771462264029602\n",
      "Test Loss: 0.3184, Test Accuracy: 0.8675\n",
      "Precision: 0.7470, Recall: 0.9142, F1-score: 0.8221\n",
      "TP: 245, FP: 83, TN: 449, FN: 23\n",
      "Epoch 64, Loss: 0.13503536758454224\n",
      "Test Loss: 0.3171, Test Accuracy: 0.8688\n",
      "Precision: 0.7447, Recall: 0.9254, F1-score: 0.8253\n",
      "TP: 248, FP: 85, TN: 447, FN: 20\n",
      "Epoch 65, Loss: 0.13113179155870489\n",
      "Test Loss: 0.3178, Test Accuracy: 0.8650\n",
      "Precision: 0.7424, Recall: 0.9142, F1-score: 0.8194\n",
      "TP: 245, FP: 85, TN: 447, FN: 23\n",
      "Epoch 66, Loss: 0.1299404537207202\n",
      "Test Loss: 0.3192, Test Accuracy: 0.8588\n",
      "Precision: 0.7356, Recall: 0.9030, F1-score: 0.8107\n",
      "TP: 242, FP: 87, TN: 445, FN: 26\n",
      "Epoch 67, Loss: 0.1261715726240685\n",
      "Test Loss: 0.3189, Test Accuracy: 0.8650\n",
      "Precision: 0.7439, Recall: 0.9104, F1-score: 0.8188\n",
      "TP: 244, FP: 84, TN: 448, FN: 24\n",
      "Epoch 68, Loss: 0.12400607196123976\n",
      "Test Loss: 0.3243, Test Accuracy: 0.8638\n",
      "Precision: 0.7446, Recall: 0.9030, F1-score: 0.8162\n",
      "TP: 242, FP: 83, TN: 449, FN: 26\n",
      "Epoch 69, Loss: 0.12034062119690996\n",
      "Test Loss: 0.3159, Test Accuracy: 0.8675\n",
      "Precision: 0.7485, Recall: 0.9104, F1-score: 0.8215\n",
      "TP: 244, FP: 82, TN: 450, FN: 24\n",
      "Epoch 70, Loss: 0.11921985506227142\n",
      "Test Loss: 0.3175, Test Accuracy: 0.8650\n",
      "Precision: 0.7454, Recall: 0.9067, F1-score: 0.8182\n",
      "TP: 243, FP: 83, TN: 449, FN: 25\n",
      "Epoch 71, Loss: 0.11634697000447072\n",
      "Test Loss: 0.3164, Test Accuracy: 0.8675\n",
      "Precision: 0.7485, Recall: 0.9104, F1-score: 0.8215\n",
      "TP: 244, FP: 82, TN: 450, FN: 24\n",
      "Epoch 72, Loss: 0.11378611486993338\n",
      "Test Loss: 0.3181, Test Accuracy: 0.8725\n",
      "Precision: 0.7594, Recall: 0.9067, F1-score: 0.8265\n",
      "TP: 243, FP: 77, TN: 455, FN: 25\n",
      "Epoch 73, Loss: 0.11189255530112668\n",
      "Test Loss: 0.3199, Test Accuracy: 0.8688\n",
      "Precision: 0.7523, Recall: 0.9067, F1-score: 0.8223\n",
      "TP: 243, FP: 80, TN: 452, FN: 25\n",
      "Epoch 74, Loss: 0.10903928487708694\n",
      "Test Loss: 0.3215, Test Accuracy: 0.8712\n",
      "Precision: 0.7538, Recall: 0.9142, F1-score: 0.8263\n",
      "TP: 245, FP: 80, TN: 452, FN: 23\n",
      "Epoch 75, Loss: 0.10618182614837822\n",
      "Test Loss: 0.3192, Test Accuracy: 0.8750\n",
      "Precision: 0.7609, Recall: 0.9142, F1-score: 0.8305\n",
      "TP: 245, FP: 77, TN: 455, FN: 23\n",
      "Epoch 76, Loss: 0.10650436521360748\n",
      "Test Loss: 0.3183, Test Accuracy: 0.8738\n",
      "Precision: 0.7569, Recall: 0.9179, F1-score: 0.8297\n",
      "TP: 246, FP: 79, TN: 453, FN: 22\n",
      "Epoch 77, Loss: 0.10218773233263116\n",
      "Test Loss: 0.3185, Test Accuracy: 0.8788\n",
      "Precision: 0.7697, Recall: 0.9104, F1-score: 0.8342\n",
      "TP: 244, FP: 73, TN: 459, FN: 24\n",
      "Epoch 78, Loss: 0.10310615138395836\n",
      "Test Loss: 0.3171, Test Accuracy: 0.8738\n",
      "Precision: 0.7585, Recall: 0.9142, F1-score: 0.8291\n",
      "TP: 245, FP: 78, TN: 454, FN: 23\n",
      "Epoch 79, Loss: 0.09895686834658447\n",
      "Test Loss: 0.3193, Test Accuracy: 0.8712\n",
      "Precision: 0.7523, Recall: 0.9179, F1-score: 0.8269\n",
      "TP: 246, FP: 81, TN: 451, FN: 22\n",
      "Epoch 80, Loss: 0.09635237251457415\n",
      "Test Loss: 0.3202, Test Accuracy: 0.8800\n",
      "Precision: 0.7687, Recall: 0.9179, F1-score: 0.8367\n",
      "TP: 246, FP: 74, TN: 458, FN: 22\n",
      "Epoch 81, Loss: 0.09647712013439129\n",
      "Test Loss: 0.3219, Test Accuracy: 0.8812\n",
      "Precision: 0.7746, Recall: 0.9104, F1-score: 0.8370\n",
      "TP: 244, FP: 71, TN: 461, FN: 24\n",
      "Epoch 82, Loss: 0.09278093631330289\n",
      "Test Loss: 0.3204, Test Accuracy: 0.8762\n",
      "Precision: 0.7666, Recall: 0.9067, F1-score: 0.8308\n",
      "TP: 243, FP: 74, TN: 458, FN: 25\n",
      "Epoch 83, Loss: 0.09080774199805762\n",
      "Test Loss: 0.3297, Test Accuracy: 0.8750\n",
      "Precision: 0.7625, Recall: 0.9104, F1-score: 0.8299\n",
      "TP: 244, FP: 76, TN: 456, FN: 24\n",
      "Epoch 84, Loss: 0.08699878246376389\n",
      "Test Loss: 0.3265, Test Accuracy: 0.8750\n",
      "Precision: 0.7609, Recall: 0.9142, F1-score: 0.8305\n",
      "TP: 245, FP: 77, TN: 455, FN: 23\n",
      "Epoch 85, Loss: 0.08692589353181814\n",
      "Test Loss: 0.3254, Test Accuracy: 0.8812\n",
      "Precision: 0.7729, Recall: 0.9142, F1-score: 0.8376\n",
      "TP: 245, FP: 72, TN: 460, FN: 23\n",
      "Epoch 86, Loss: 0.08428675720566198\n",
      "Test Loss: 0.3235, Test Accuracy: 0.8762\n",
      "Precision: 0.7632, Recall: 0.9142, F1-score: 0.8319\n",
      "TP: 245, FP: 76, TN: 456, FN: 23\n",
      "Epoch 87, Loss: 0.08218525859870408\n",
      "Test Loss: 0.3345, Test Accuracy: 0.8775\n",
      "Precision: 0.7673, Recall: 0.9104, F1-score: 0.8328\n",
      "TP: 244, FP: 74, TN: 458, FN: 24\n",
      "Epoch 88, Loss: 0.08223609028286055\n",
      "Test Loss: 0.3294, Test Accuracy: 0.8750\n",
      "Precision: 0.7609, Recall: 0.9142, F1-score: 0.8305\n",
      "TP: 245, FP: 77, TN: 455, FN: 23\n",
      "Epoch 89, Loss: 0.07974216234135001\n",
      "Test Loss: 0.3313, Test Accuracy: 0.8775\n",
      "Precision: 0.7640, Recall: 0.9179, F1-score: 0.8339\n",
      "TP: 246, FP: 76, TN: 456, FN: 22\n",
      "Epoch 90, Loss: 0.07814898557568851\n",
      "Test Loss: 0.3324, Test Accuracy: 0.8762\n",
      "Precision: 0.7600, Recall: 0.9216, F1-score: 0.8331\n",
      "TP: 247, FP: 78, TN: 454, FN: 21\n",
      "Epoch 91, Loss: 0.07696075639442394\n",
      "Test Loss: 0.3348, Test Accuracy: 0.8762\n",
      "Precision: 0.7666, Recall: 0.9067, F1-score: 0.8308\n",
      "TP: 243, FP: 74, TN: 458, FN: 25\n",
      "Epoch 92, Loss: 0.07690350819183023\n",
      "Test Loss: 0.3301, Test Accuracy: 0.8800\n",
      "Precision: 0.7722, Recall: 0.9104, F1-score: 0.8356\n",
      "TP: 244, FP: 72, TN: 460, FN: 24\n",
      "Epoch 93, Loss: 0.07431726804689358\n",
      "Test Loss: 0.3359, Test Accuracy: 0.8800\n",
      "Precision: 0.7774, Recall: 0.8993, F1-score: 0.8339\n",
      "TP: 241, FP: 69, TN: 463, FN: 27\n",
      "Epoch 94, Loss: 0.07223860743014436\n",
      "Test Loss: 0.3369, Test Accuracy: 0.8788\n",
      "Precision: 0.7714, Recall: 0.9067, F1-score: 0.8336\n",
      "TP: 243, FP: 72, TN: 460, FN: 25\n",
      "Epoch 95, Loss: 0.07010321083821748\n",
      "Test Loss: 0.3364, Test Accuracy: 0.8838\n",
      "Precision: 0.7796, Recall: 0.9104, F1-score: 0.8399\n",
      "TP: 244, FP: 69, TN: 463, FN: 24\n",
      "Epoch 96, Loss: 0.06898785696217888\n",
      "Test Loss: 0.3341, Test Accuracy: 0.8750\n",
      "Precision: 0.7727, Recall: 0.8881, F1-score: 0.8264\n",
      "TP: 238, FP: 70, TN: 462, FN: 30\n",
      "Epoch 97, Loss: 0.06881856781087424\n",
      "Test Loss: 0.3457, Test Accuracy: 0.8788\n",
      "Precision: 0.7749, Recall: 0.8993, F1-score: 0.8325\n",
      "TP: 241, FP: 70, TN: 462, FN: 27\n",
      "Epoch 98, Loss: 0.06798611370552528\n",
      "Test Loss: 0.3398, Test Accuracy: 0.8800\n",
      "Precision: 0.7774, Recall: 0.8993, F1-score: 0.8339\n",
      "TP: 241, FP: 69, TN: 463, FN: 27\n",
      "Epoch 99, Loss: 0.06525533048338011\n",
      "Test Loss: 0.3388, Test Accuracy: 0.8738\n",
      "Precision: 0.7634, Recall: 0.9030, F1-score: 0.8274\n",
      "TP: 242, FP: 75, TN: 457, FN: 26\n",
      "Epoch 100, Loss: 0.06384680292716152\n",
      "Test Loss: 0.3396, Test Accuracy: 0.8812\n",
      "Precision: 0.7818, Recall: 0.8955, F1-score: 0.8348\n",
      "TP: 240, FP: 67, TN: 465, FN: 28\n"
     ]
    }
   ],
   "source": [
    "stats = dict()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loss = trainLoop(model, optimizer, criterion, train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
    "    pred_function = lambda x: x > 0.2\n",
    "    testLoop(model, criterion, test_loader, pred_function, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_stats(\"MLP_V1_bert_base\", stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atcs_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
