{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, 'r', encoding='utf-8') as json_file:\n",
    "        try:\n",
    "            return json.load(json_file)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error reading {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(json_as_dict: dict):\n",
    "    tokens_embedding = []\n",
    "    for key in json_as_dict:\n",
    "        value = json_as_dict[key]\n",
    "        \n",
    "        if isinstance(value, list):\n",
    "            tokens = []\n",
    "            for elem in value:\n",
    "                tokens.extend(word_tokenize(elem.lower()))\n",
    "        else:\n",
    "            tokens = word_tokenize(value.lower())\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in model:\n",
    "               tokens_embedding.append(model[token])\n",
    "    \n",
    "    embedding = np.mean(tokens_embedding, axis=0) if tokens_embedding else np.zeros(model.vector_size)\n",
    "\n",
    "    return np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dataset_entries = []\n",
    "\n",
    "path2id = dict()\n",
    "id2embedding = dict()\n",
    "\n",
    "GROUND_TRUTH_PATH = 'dataset/monitor_entity_resolution_labelled.csv'\n",
    "DATASET_PATH = \"dataset/2013_monitor_specs/\"\n",
    "\n",
    "numberOfZeros = 0\n",
    "numberOfOnes = 0\n",
    "\n",
    "with open(GROUND_TRUTH_PATH, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for index, row in enumerate(csv_reader):\n",
    "        print(\"\\r\"+str(index), end=\"\")\n",
    "        if index == 0:\n",
    "            dataset_entries.append(row)\n",
    "            continue\n",
    "        left_folder, left_id = row[0].split(\"//\")\n",
    "        right_folder, right_id = row[1].split(\"//\")\n",
    "        label = int(row[2])\n",
    "\n",
    "        if label == 0: numberOfZeros += 1\n",
    "        else: numberOfOnes += 1\n",
    "\n",
    "        left_path = DATASET_PATH + left_folder + \"/\" + left_id + \".json\"\n",
    "        right_path = DATASET_PATH + right_folder + \"/\" + right_id + \".json\"\n",
    "\n",
    "        if left_path in path2id:\n",
    "            left_id = path2id[left_path]\n",
    "        else:\n",
    "            left_id = len(path2id)\n",
    "            id2embedding[left_id] = get_embedding(load_json(left_path))\n",
    "            path2id[left_path] = left_id\n",
    "\n",
    "        if right_path in path2id:\n",
    "            right_id = path2id[right_path]\n",
    "        else:\n",
    "            right_id = len(path2id)\n",
    "            id2embedding[right_id] = get_embedding(load_json(right_path))\n",
    "            path2id[right_path] = right_id\n",
    "\n",
    "        dataset_entries.append([left_id, right_id, label])\n",
    "dataset = pd.DataFrame(dataset_entries[1:], columns=dataset_entries[0])\n",
    "shuffled_dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_dataset.to_csv('dataset.csv', index=False)\n",
    "\n",
    "print()\n",
    "print(numberOfZeros)\n",
    "print(numberOfOnes)\n",
    "\n",
    "with open('id2embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(id2embedding, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
